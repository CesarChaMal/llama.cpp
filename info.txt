git stash
git pull origin master
git stash pop

git reset --hard origin/master

git clean -fd

conda create --name llama.cpp python=3.1
conda create --name llama.cpp python=3.8
conda activate llama.cpp
conda info --envs

git clone https://github.com/CesarChaMal/llama.cpp.git
mv llama.cpp/* .

apt install git-lfs
git lfs install

apt install -y cmake
apt install -y make
cmake ..
make

git clone https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B openHermes-7b-v2.5
mv openHermes-7b-v2.5 models/

git clone https://huggingface.co/teknium/OpenHermes-7B openHermes-7b
mv openHermes-7b models/

python3 convert.py ./models/openHermes-7b-v2.5 --outfile ./models/openHermes-7b-v2.5/ggml-model-f16.gguf --outtype f16
python3 convert.py ./models/openHermes-7b --outfile ./models/openHermes-7b/ggml-model-f16.gguf --outtype f16

apt install python3-pip
pip install -r requirements.txt
pip install sentencepiece

sudo apt update
sudo apt install -y libimagequant-dev

./quantize models/openHermes-7b-v2..5/ggml-model-f16.gguf models/openHermes-7b-v2..5/ggml-model-q8_0.gguf q8_0
./quantize models/openHermes-7b/ggml-model-f16.gguf models/openHermes-7b/ggml-model-q8_0.gguf q8_0

./quantize models/openHermes-7b-v2..5/ggml-model-f16.gguf models/openHermes-7b-v2..5/ggml-model-q4_k.gguf q4_k
./quantize models/openHermes-7b/ggml-model-f16.gguf models/openHermes-7b/ggml-model-q4_k.gguf q4_k

./batched-bench ./models/openHermes-7b-v2.5/ggml-model-f16.gguf 4096 0 99 0 2048 128,512 1,2,3,4
./batched-bench ./models/openHermes-7b/ggml-model-f16.gguf 4096 0 99 0 2048 128,512 1,2,3,4

./server -m models/openHermes-7b-v2.5/ggml-model-q4_k.gguf --port 8888 --host 0.0.0.0 --ctx-size 10240 --parallel 4 -ngl 99 -n 512
./server -m models/openHermes-7b/ggml-model-q4_k.gguf --port 8888 --host 0.0.0.0 --ctx-size 10240 --parallel 4 -ngl 99 -n 512


